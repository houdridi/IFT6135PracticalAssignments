{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Hyperparameters Optimization - Keras - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import InputLayer, Input\n",
    "from tensorflow.python.keras.layers import Reshape, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.python.keras.optimizers import sgd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t60000\n",
      "- Test-set:\t\t10000\n",
      " Shape of train target set:(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(x_train.shape[0]))\n",
    "print(\"- Test-set:\\t\\t{}\".format(x_test.shape[0]))\n",
    "print(\" Shape of train target set:{}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform a one hot encoding on _y_train_ so that it have the sahpe (60000,10):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y_train.reshape(-1, 1))\n",
    "y_train_onehot = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_train_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for _y_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(y_test.reshape(-1, 1))\n",
    "y_test_onehot = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
    "y_test_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "batch_size = [128,256]\n",
    "learning_rate = [0.01,0.001]\n",
    "output_channels = [[512,128],[128,512],[256,256]]\n",
    "activation_fct = ['sigmoid','tanh','relu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def create_model(activation_fct='relu',learning_rate=0.001,output_channels = [512,128]):\n",
    "    # Start construction of the Keras Sequential model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an input layer \n",
    "    model.add(InputLayer(input_shape=((28, 28))))\n",
    "\n",
    "    # Convolutional layers expect images with shape (28, 28, 1)\n",
    "    model.add(Reshape((28, 28, 1)))\n",
    "\n",
    "    # First convolutional layer with ReLU-activation and max-pooling.\n",
    "    model.add(Conv2D(kernel_size=3, strides=2, filters=output_channels[0], padding='same',\n",
    "                     activation=activation_fct, name='layer_conv1'))\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "    # Second convolutional layer with ReLU-activation and max-pooling.\n",
    "    model.add(Conv2D(kernel_size=3, strides=2, filters=output_channels[1], padding='same',\n",
    "                     activation=activation_fct, name='layer_conv2'))\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "    # Flatten the 4-rank output of the convolutional layers to 2-rank that can be input to a fully-connected / dense layer.\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Last fully-connected / dense layer with softmax-activation for use in classification.\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    optimizer = sgd(lr=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, verbose=1)\n",
    "# parameters dictionary\n",
    "param_grid = dict(batch_size=batch_size,\n",
    "                  learning_rate=learning_rate,\n",
    "                  output_channels=output_channels)\n",
    "# perform grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(x_train, y_train_onehot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.968217 using {'batch_size': 128, 'learning_rate': 0.001, 'output_channels': [512, 128]}\n",
      "0.104100 (0.007320) with: {'batch_size': 128, 'learning_rate': 0.01, 'output_channels': [512, 128]}\n",
      "0.095050 (0.003091) with: {'batch_size': 128, 'learning_rate': 0.01, 'output_channels': [128, 512]}\n",
      "0.099983 (0.004962) with: {'batch_size': 128, 'learning_rate': 0.01, 'output_channels': [256, 256]}\n",
      "0.968217 (0.001370) with: {'batch_size': 128, 'learning_rate': 0.001, 'output_channels': [512, 128]}\n",
      "0.719600 (0.161870) with: {'batch_size': 128, 'learning_rate': 0.001, 'output_channels': [128, 512]}\n",
      "0.936750 (0.042957) with: {'batch_size': 128, 'learning_rate': 0.001, 'output_channels': [256, 256]}\n",
      "0.101133 (0.003080) with: {'batch_size': 256, 'learning_rate': 0.01, 'output_channels': [512, 128]}\n",
      "0.102283 (0.004754) with: {'batch_size': 256, 'learning_rate': 0.01, 'output_channels': [128, 512]}\n",
      "0.095833 (0.003475) with: {'batch_size': 256, 'learning_rate': 0.01, 'output_channels': [256, 256]}\n",
      "0.927750 (0.043392) with: {'batch_size': 256, 'learning_rate': 0.001, 'output_channels': [512, 128]}\n",
      "0.739317 (0.314747) with: {'batch_size': 256, 'learning_rate': 0.001, 'output_channels': [128, 512]}\n",
      "0.927733 (0.045071) with: {'batch_size': 256, 'learning_rate': 0.001, 'output_channels': [256, 256]}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
